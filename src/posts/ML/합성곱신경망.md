---
title: '합성곱신경망(CNN)'
date: '2020-06-26'
category: ['딥러닝', '머신러닝']
draft: false
---

### 합성곱 신경망 (CNN)

`CNN`은 이미지 인식과 음성인식 등 다양한 곳에서 사용되고있고,
특히 **이미지 인식** 딥러닝의 기초가 된다.

### 7.1 전체구조

`합성곱 계층과(convolutional layer)` `풀링 계층(pooling layer)`이 등장한다.

지금까지의 신경망은 인접 계층의 모든 뉴런과 결합되어있었고, 이를 완전연결(`fully-connected`/ 완전결합)이라고 한다.
완전히 연결된 계층을 **`Affine 계층`이라는 이름으로 구현**했다.

> 합성곱 : 두 함수중 하나를 reverse or shift 시켜가면서 나머지 함수와의 곱을 연이어 적분한다.

### `Affine`와 `CNN`의 차이

-   `Affine` : input -> **Affine-ReLU -> Affine-ReLU** -> Affine-Softmax
-   `CNN` :
    input -> **Conv- ReLU-Polling** -> Conv-ReLU-Polling-> **Conv-ReLU** -> Affine-ReLU -> Affine-Softmax

    이처럼 **CNN계층에서 Pooling 계층은 생략**될수도 있다.

### 합성곱 계층

CNN에서는 `패딩(Padding)`, `스트라이드(Stride)`와 같은 CNN 고유의 용어가 등장한다.또한 각 계층사이에는 입체적인 data가 흐른다.

-   **완전연결 계층의 문제점**  
    지금까지 본 완전연결 신경망에서는 완전연결계층(**affine** 계층)을 사용했다.
    이에서는 **인접하는 계층의 뉴런이 모두 연결되고 출력의 수는 임의로 정할수 있다.**

    이때의 문제점은 **data형상이 무시**된다는 것이다.

ex) img 의 경우 가로,세로,깊이(색상)으로 구성된 3차원 data인데 affine에 입력할때는 1차원으로 `flatten`해줘야한다. 지금까지의 **_MNIST는 1x28x28의 이미지를 1x784로 평탄화_** 해서 Affine계층에 입력했다.
따라서 이런경우 3차원상에서 가까운 픽셀끼리 상관관계나 어떠한 규칙성이라는게 있을수 있는데 1차원으로 입력이 들어가게되면 그러한 정보들은 살릴 수가 없다.

반면 **합성곱 계층은 이러한 형상을 유지한채 처리하고 전달**해주기 때문에 제대로 이해할 가능성이 있다.

CNN에서는 합성곱계층의 입출력 데이터를 `feature map`이라고 하는데 합성곱 계층의 입력 data를 input feature map , 출력데이터를 output feature map 이라고 한다.

-   **_합성곱 연산_**
    img 처리에서 말하는 `filter` 연산을 말한다.
    즉 합성곱 연산은 입력 데이터와 필터(커널) 그리고 출력이 있다.

*   연산 방법:  
    필터의 `window`를 일정 간격 이동해가면서 `input data`에 적용해주는 것이다. 이때 필터에 대응하는 연산을 처리해준다.
    (**_단일 곱셈 누산_** : **_Fused Multiply Add/ FMA_**
    대응하는 원소끼리 곱한 후 총합을 구하는것,)

> scipy에서 2차원 합성곱함수로 예를 따라해보면 다른 결과가 나오는데
> 그이유는 scipy에서는 교차상관으로 해야하기때문이다. 교차상관은 FMA에서 filter를 flipping 해준 것이고 이때의 flipping이란 좌우 상하 한번씩 뒤집는 것을 말한다.(deep learning에서는 flipping을 따로 구분하지 않는다.)

CNN에서는 **_필터의 매개변수_**가 그동안의 **_가중치와 같은 역할_**을 하고,
편향의 경우에는 필터를 다 적용한 후 data에 더한다.(편향은 항상 1개만 존재한다.)

### 패딩(padding)

합성곱 연산을 수행하기전에 **_input data주변을 0으로 채우기도 한다_**.
패딩은 주로 출력 크기를 조절할 목적으로 사용하는데, 왜냐하면 합성곱연산을 되풀이하는 심층 신경망에서는 출력이 작아지면 다음의 입력도 작아지므로 문제가 될수 있어서이다.(어느순간 1이되어버림).따**_따라서 패딩을 줌으로써 입력크기 그대로 다음 층에 넘겨줄수 있다_**.

### 스트라이드(stride)

필터를 적용하는 위치간격을 스트라이드라고 한다.
(**_윈도우가 이동하는 간격을 조정_**한다)
(따라서 스트라이드 크기를 키우면 출력 크기가 줄어든다)

### 패딩과 스트라이드 출력크기 계산

입력크기를(H,W),필터 크기를 (FH, FW), 출력크기를 (OH,OW), 패딩을 P, 스트라이드 S
`OH = (H + 2P -FH)/s + 1`
`OW = (W + 2P - FW)/S + 1`
글로 풀어서 나타내보면
`출력 = (입력 + 2x패팅 - 필터) /스트라이드 + 1`

이때 Output이 정수로 나와야하는데 딥러닝 프레임워크중에는 정수가 안나오면 가까운 정수로 반올림하는 방법을 사용해주는 애도 있다.

### 3차원에 적용시켜보기

만약 깊이라는 차원이 추가 되었다면 가로 세로에 대해서 합성곱 연산을 먼저 수행하고 그 결과를 더해서 출력을 얻으면 된다.

이때 주의사항으로는 input의 channel 수와 필터의 채널수가 같아야 한다는 것
(그리고 각 채널들이 모두 같은 크기여야한다 )

무슨말인지 보면
3차원 데이터를 다차원 배열로 나타낼때는`(C,H,W)` (순서대로 채널, 높이, 너비다)
필터도 이와 같이 `(C,FH,FW)`로 쓴다.

필터를 그냥 1개의 필터(여기서 필터 1개라 하면 정육면체 모양의 깊이가 있는 필터이지만 채널의 계산 결과를 합쳐서 1개의 값으로 변환하기때문에 출력값은 **깊이가 1인 output이 나오게 된다**. 따라서 다음으로 전해주기위해서 출력도 여러개로 하고싶으면 **_필터를 복수개 적용시켜 주면 된다_** .)

```
(C, H , W ) ⨀ (FN, C, FH , FW) --> (FN, OH,OW) + (FN,1,1) --> (FN,OH,OW)
```

이렇게 연산에서 필터의 수도 고려해줘야하는데, 따라서 필터의 **_가중치 data는 4차원의 모양으로 작성해준다_** (출력갯수, 입력채널수, 높이, 너비)

### 배치처리

합성곱 연산도 배치처리를 지원한다.
따라서 각 계층의 차원을 늘려서 4차원으로 저장하는데
(data수, 채널수, 높이, 너비) 순서로 저장한다..

```
(N,C, H , W ) ⨀ (FN, C, FH , FW) --> (N,FN, OH,OW) + (FN,1,1) --> (N,FN,OH,OW)
```

이 흐름은 한번 흘러갈때마다 `data N개`에 대한 합성곱 연산이 이뤄진다는 것이 배치처리의 주요 포인트다.

### 풀링계층(Pooling)

풀링은 가로 세로 방향의 공간을 줄이는 연산이다.
풀어서 작성해보면 풀링이란 filter의 윈도우로 대상영역(2x2 필터의 영역과 비슷)에서 특정 규칙을 기준으로 값을 뽑아내 data 공간을 줄이는 것이다.
이때 **_대상영역(window)의 크기와 스트라이드(이동간격)은 같은 값으로 설정하는게 보통이다._**

> 풀링의 종류에는 **_최대 풀링_** 외에도 **_평균 풀링_**등이 있다.(이미지 분야에서는 최대풀링을 사용한다.)

#### 풀링계층의 특징

-   학습해야할 매개변수가 없다.==> 대상영역에서 바로 특정 처리를 하는것이므로 학습할 것이 없다.
-   채널 수가 변하지 않는다 ==> 입력 채널수 그대로 출력 데이터로 보낸다(독립적으로 계산된다.)
-   입력의 변화에 영향을 적게 받는다 (입력data가 조금 변해도 풀링의 결과는 같게 나올수 있다는 말이다.)

### 합성곱계층 구현하기

4차원 배열

```python
x = np.random.rand(10,1,28,28)
x.shape  # (10,1,28,28)

x[0].shape #(1,28,28)
```

> `im2col`로 데이터 전개하기  
> 원래 합성곱 연산을 그대로 구현하려면 for문을 써야하겠지만 그렇게 되면 **_복잡+ 성능저하_**가 생긴다. 따라서 `im2col`함수를 이용해서 간단하게 구현해보자

`im2col` : input data를 필터링하기 좋게 전개하는 함수이다.
(구체적으로는 필터를 적용하는 영역을 **_한 row로 변환해서 전개_**한다.)
대신 스트라이드에 따라서 필터링시 겹치는 영역이 생길수있는데 그렇게 되면 `im2col`로 전개할때 row의 갯수가 많아지게 되고 이는 memory를 많이 소비하는 단점이있다. 하지만 그러한 단점에도 불구하고 **_컴퓨터는 행렬의 계산에 특화되어있으므로 문제를 행렬로 단순화 시키면 효율을 높일 수 있다_**.

즉 이 말처럼 `im2col`은 `image to column`의 줄임말이다.

input data를 행렬로 바꿔 주었으니 여러장의 filter 또한 행렬의 column으로 바꿔서 행렬의 곱을 수행해주자
그리고 이러한 행렬의 곱 이후에는 **_output data가 2차원이므로 reshape를 통해서 다시 4차원으로 변형_**해줘야한다.

`im2col` 을 이용해서 구현하면 손쉽게 전개하여 연산해줄 수있는데
이를 통해 `Affine`계층과 거의 유사한 프로세스로 구현할숭 있다.

단 주의할것은 im2col을 이용한 함수의 역전파는 `col2im`을 사용하면 되는데
이 부분만 제외하면 Affine계층과 똑같다.

### 풀링계층 구현하기

풀링계층또한 `im2col`을 사용해서 data를 전개하는데 대신 이때 채널이 독립적으로 보전이 되기때문에 약간의 차이가 있다.

이채널의 구분은 그냥 1~4row까지는 채널 1, 이런식으로 구분해주면 된다
그리고 **각 row에서 최댓값을 뽑아내서 순서대로 2x2에다가 넣어주고 data의 갯수는 유지해준다**

###### 풀링계층의 구현 단계

1. 입력 데이터를 전개한다
2. 행별 최댓값을 구한다
3. 적절한 모양으로 성형한다.

이때 최댓값은 `np.max`를 사용해서 구현할수있는데 추가로 축 axis를 지정하면 축마다 최댓값을 구할 수 있다..

이렇게 구현된 합성곱계층과 풀링계층은 img인식에 필수적인 모듈이다.
왜냐면 공간적인 형상을 학습에 반영해서 할수 있으므로 CNN이 손글씨 숫자인식을 하기 수월해지는 것이다.

## CNN시각화 하기

> 학습이 된 규칙성있는 필터는 무엇을 보는 걸까?
> `Edge`(색상이 변하는 경계선)와 `Blob`(국소적으로 덩어리진 영역)등을 보고있다.
> 이러한 정보들이 뒤로 전달되는게 CNN에서 일어나고 있는 일들이다.

층이 깊어진다면
첫번째 층에서 **edge와 blob** 3번째 층에서 **texture**, 5번째 층에서 **object part**
마지막 층에서 **object class**이런식으로 뉴런이 반응한다.
즉 여러겹 쌓아 나가면 층이 깊어질수록 복잡하고 추상화된 정보를 추출할수있다.

### 대표적인 CNN

#### LeNet

`합성곱 계층`과 `subsampling` 계층을 반복하고 완전연결계층을(`Affine`) 거치면서 출력하는데 활성화 함수를 `sigmoid`로 사용하고 서브샘플링을 통해 중간 data의 크기를 줄이는데 현재의 CNN과 차이가 있는 초기 모델이다.

#### AlexNet

`합성곱 계층`과 `풀링계층`을 거치고 마지막으로 `완전연결계층`을 거쳐 결과를 출력하는데 활성화 함수로 `ReLU`를 이용한다.
`LRN(Local Response Normalization)`이라는 국소적 정규화를 실시하는 계층을 이용하고, `Dropout`을 이용한다

이러한 모델의 개발뿐만아니라. 병렬계산에 특화된 GPU가 보급되고
빅데이터를 통해서 매개변수 pitting등 의 해결책 제시덕분에 요즘의 CNN은 보다 진보된 성능을 보이고있다.

### 👨‍💻 실습코드

```python
import im2col
import sys
import os
sys.path.append(os.pardir)

# im2col(input_data, filter_h, filter_w, stride, pad)

x1 = np.random.rand(1, 3, 7, 7)
col1 = im2col(x1, 5, 5, stride=1, pad=0)
print(col1.shape)  # (9,75)

x2 = np.random.rand(10, 3, 7, 7)
col2 = im2col(x2, 5, 5, stride=1, pad=0)

print(col2.shape)  # (90,75)

# 이때 출력되는 75의 크기는 필터의 원소수와 같다(3*5*5)


class Convolution:
    def __init__(self, W, b, stride=1, pad=0):
        self.W = W
        self.b = b
        self.stride = stride
        self.pad = pad

    def forward(self, x):
        FN, C, FH, FW = self.W.shape
        N, C, H, W = x.shape
        out_h = int(1 + (H+2*self.pad - FH) / self.stride)
        out_w = int(1 + (W+2*self.pad-FW)/self.stride)

    # ##########################
        col = im2col(x, FH, FW, self.stride, self.pad)
        col_W = self.W.reshape(FN, -1)).T  # 필터 전개, reshape -1을 지정하면
                        # 다차원 배열에서 원소수가 변환 후에도 똑같이 유지되도록 묶어준다.
                        # 즉 (10,3,5,5)는 총 750개의 원소인데 reshape(10,-1)을 하면 (10,75)로 묵어주는 것이다.
        out=np.dot(col, col_w) + self.b
    # 중요한 부분

        out=out.reshape(N, out_h, out_w, -1).transpose(0, 3, 1, 2)
        # transpose함수를 이용하는데 이는 axis의 순서를 바꿔주는 것이다.
        # (N,H,W,C)/ 0,1,2,3 ==transpose ==> (N,C,H,W) / 0,3,1,2
        return out


class Pooling:
    def __init__(self, poll_h, pool_w, stride = 1, pad = 0):
        self.pool_h=pool_h
        self.pool_w=pool_w
        self.stride=stride
        self.pad=pad

    def forward(self, x):
        N, C, H, W=x.shape
        out_h=int(1+(H-self.pool_h)/self.stride)
        out_w=int(1 + (W-self.pool_w)/self.stride)

        # 전개1
        col=im2col(x, self.pool_h, self.stride, self.pad)
        col=col.reshape(-1, self.pool_h*self.pool_w)

        # 최댓값2
        out=np.max(col, axis = 1)

        # 성형
        out=out.reshape(N, out_h, out_w, C).transpose(0, 3, 1, 2)
        return out

```
