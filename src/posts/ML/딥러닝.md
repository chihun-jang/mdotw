---
title: '딥러닝 개론'
date: '2020-06-27'
category: ['딥러닝', '머신러닝']
draft: False
---

> 딥러닝 : 딥러닝은 층을 깊게 한 심층 신경망이다.

자주 쓰이는 딥러닝의 모양(2017기준)

-   활성화 함수를 `ReLU`로 사용
-   완전연결계층 뒤에 `Dropout`계층사용
-   `Adam`을 사용해 최적화
-   가중치 초깃값은 "`He` 초깃값"

이를 이용하면 인식률을 높일수 있는데, 이를 통해 우리 사람들의 인식률을 뛰어넘는 인식률도 선보이고 있다.

> **_What is the class of this image?_**
> 사이트를 보면 다양한 dataset을 대상으로 그동안 사용하는 기법들의 정확도를 정리해두었다.

MNIST 문제의 경우에는 일반적 문제에 비해서 비교적 단순해서 층을 굳이 깊게 안해도 되지만 **_일반 사물인식에서는 층을 깊게하면 정확도 개선에 효과_**가 있다.

> 정확도 향상에 도움이 되는 것들 : **_앙상블학습_**, **_학습률감소_**, **_데이터확장_**

-   **_데이터확장_** : **_train img 를 인위적으로 확장한다. 회전을 하거나 이동을하거나. data가 별로 없을때 효과적이다_**.(crop, flip 포함)

> 층을 깊게하는게 중요한 이유  
> 사실 이론적으로 근거가 탄탄한 것은 아니지만 층을 깊게한 결과로 정확도가 좋아지기때문에, 이점으로는 적은 매개변수로 같거나 그 이상의 표현력을 달성할 수있다.

> ex) **_5X5 합성곱 연산 1회는 3X3연산 2회를 수행해서 대체_**할수 있다.
> **_매개변수도 25개와 18개로 갯수가 적어_**진다.

> **작은 필터를 겹쳐서 신경망을 깊게할때 장점은 매개변수 수를 줄여 넓은 수용영역을 소화**할수 있다는데 있다.(수용영역이란 뉴런의 변화를 일으키는 공간영역), **층을 거듭하면서 ReLU등 활성화 함수를 합성곱 계층 사이에 끼워넣어서 신경함수의 표현력이 개선**된다.(활성화 함수가 비선형이고, 이를 통해서 더 복잡한 것도 표현할수 있기 때문)

학습의 효율성측면에서도 층을 깊게하는게 이점이다. 층을 깊게해서**_train data양을 줄여 고속으로 수행_**할수있는데 앞장에서 보면 층이 깊어질수록 사물에 대한 이해가 깊어졌던만큼 개(dog)를 분류하는 문제가 있다고 할때 얕은 신경망의 경우에는 개(dog)의 특징을 한번에 많은 것을 이해해야하므로 data도 많이 필요하고 학습시간도 오래 걸리게 된다.

따라서 **계층적으로 해주게 되면 각 계층마다 특정 단순문제에 더 집중할수있어서 좋다.**(이 모두는 빅데이터와 GPU로 인해 가능해졌다.)

---

딥러닝이 주목받기 시작한것은 2012년 ILSVRC에서 `AlexNet`이 등장하면서 부터였는데 ILSVRC에는 이미지넷(100만장)을 1000개의 클래스로 분류하는 문제 등이있었다. 우수한 성적을 거둔 모델로 VGG,GoogLeNet, ResNet이 유명하다.

### VGG

`VGG`는 구성이 간단해서 응용하기 좋은데 16층을 두고 풀링층을 통과하며 크기가 절반으로 줄어드는 처리가 반복된다.

### GoogLeNet

깊이뿐만 아니라 너비도 깊어지고 있는데 이를 **_인셉션 구조_**라 하며 크기가 다른 필터,풀링을 여러개 적용하여 결과를 결합한다.
그리고 **1X1 크기의 필터 합성곱**을 많은 곳에 사용하는데 이는 **채널쪽의 크기를 줄이고 매개변수 제거 및 고속처리에 기여**한다.

### ResNet

마이크로소프트 팀이 개발한 Network로 층이 지나치게 깊으면 성능이 떨어지고 학습이 잘되지않는 것을 `skip connection`을 도입해서 해결했다.

skip connection의 핵심은 **_input data를 합성곱 계층을 건너뛰어 출력에 바로 더하는 구조_**이다.(왜냐하면 역전파때 스킵연결이 신호감쇠를 막아주기때문이다.)

스킵연결은 input data를 그대로 흘리는 것으로 **_역전파시에도 상류의 기울기를 그대로 하류로 흘려보낸다_**.(아무런 수정도 하지 않고.)

> 이렇게 이미지넷에서 제공한 dataset으로 학습한 가중치값들을 실제 제품에도 활용하는데. 이를 **_전이학습_**이라 한다. 이는 학습된 가중치를 다른 신경망에 복사한다음 그상태로 재학습을 수행하는 것을 말한다. 이는 학습할 dataset이 적을때 유용하다.(fine tuning)

---

### 더 빠르게 (딥러닝 고속화)

최근 딥러닝 프레임워크 대부분은 `GPU(Graphics Processing Unit)`을 활용해
대량의 연산을 고속으로 처리한다.

AlexNet의 경우 forward 처리(순전파) 에서는 합성곱계층 처리시간이
GPU에서 95퍼 CPU에서 89퍼에 이른다.

GPU는 원래 그래픽 전용보드에 이용했는데 이를 범용 수치연산에도 이용하기 시작했고. 이에 GPU는**_ 병렬 수치연산을 고속으로 처리_**할 수 있다..

딥러닝에서 수행하는 단일곱셈-누산(혹은 행렬끼리의 곱)은 병렬연산으로 GPU의 특기이다. 한편 **_CPU는 연속적인 복잡한 계산을 잘 처리_**한다.

GPU는 주로 NVIDIA와 AMD 두 회사가 제공하는데, 딥러닝과 더 친한 쪽은 NVIDIA쪽이다. 실제로 대부분의 딥러닝 프레임워크는 엔비디아 GPU에서만 혜택을 받을수있다.

이는 NVIDIA GPU컴퓨팅용 통합 개발환경인 `CUDA`를 사용하기 때문이다.
cuDNN또한 CUDA위에서 동작하는 lib이다.

---

### 분산학습

이처럼 딥러닝을 학습하는데 걸리는 시간을 단축하고싶다는 요구가 생겨났다.
따라서 **_수평확장(분산학습)_**이 등장하게된다.

최근에는 다수의 GPU와 computer를 이용한 분산학습을 지원하는 deeplearning framework가 생겨나고있는데
그중에서 **_구글의 텐서플로와 CNTK (computational Network Toolkit)_**은 분산학습에 초점이 맞춰져있다..

큰 data center의 `low latency, high throughput` 네트워크 위에서 이 프레임워크들의 분산학습은 놀라운 효과가 있었다.

---

### 연산 정밀도와 비트줄이기

계산 외에도 **_memory용량_** 과 **_버스 대역폭_**등이 DL고속화의 `병목지점`이 될수잇는데 memory용량은 **_가중치 매개변수와 중간 data를 메모리에 저장_**하는 것, **버스 대역폭은 GPU의 버스를 흐르는 data가 많아져 문제가 생기는 것**이 있는데 따라서 **_데이터의 `비트수는 최소로` 만드는 것이 좋다_**.

다행히 DL은 높은 수치정밀도를 요구하지 않는다
이로써 이미지에 노이즈가 섞여있어도, 혹은 data를 퇴화 시켜도 출력에 주는 영향은 미미하다..

32비트 단정밀도, 64비트 배정밀도의 포맷이있지만
**_16비트 반정밀도만 사용해도 문제가 없다한다_**.(파스칼 아키텍쳐는 이 포맷을 지원(2016))

파이썬의 numpy도 16비트를 지원하는데 이를 사용해도 정확도가 떨어지지 않는 것을 확인할 수 있고, 다만 storage가 16비트지 연산이 16비트는 아니다.

최근에는 가중치와 중간데이터를 1비트로 표현하는 `Binarized NN`방법도 등장.

---

### 딥러닝 활용

사물인식, 이미지, 음성,자연어 등의 분야가있는데

-   사물검출  
    `R-CNN(Regions with CNN)`을 이용하여 이미지 내 사물을 검출한다.
    **후보영역을 추출하고 CNN계산을 하고 영역을 분류**하는 작업이다.

    이때 후보영역 추출에는 컴퓨터 비전분야가 개입이되는데
    R-CNN논문에는 Selective Search기법이 이용되어 있다..
    이 **영역 추출까지 CNN으로 처리하는 Faster R-CNN기법도 등장**했다

-   분할  
    이미지를 픽셀 수준에서 분류하는 문제, 픽셀단위로 채색된 supervised data를 사용해서 학습. 가장 단순한 방법으로는 모든 픽셀을 추론하는건데.
    너무 시간이 오래걸린다. 따라서 `FCN(Fully Convolutional Network)`(합성곱계층만으로 구현된 Network) 가 고안되었고
    한번의 **forward 처리로 모든 픽셀 클래스를 분류해주는 기법**이다.

    사물인식에서는 완전연결계층에서 중간 data의 공간 볼륨을 1차원으로 변환해서 처리했지만 **FCN은 그 볼륨을 유지한채 마지막까지 가져간다.**
    (찾아볼 키워드 : 이중선형보간, 역합성곱)

-   사진 캡션 생성  
    `NIC(심층 CNN과 자연어 혹은 시계열 데이터를 다우는 RNN(Recurrent NN))`로 구성된다.

    **CNN으로 사진에서 특징을 추출하고 특징을 RNN에 넘겨 처리**한다.
    이렇게 두개 이상의 정보를 처리하는 것을 멀티모달(multi-modal)처리라고 하고 주목받는 분야이다.

> RNN은 순환적인만큼 **이전에 생성한 정보에 영향을 받아서 새로운 데이터를 예측**한다.

-   이미지 스타일 변환  
    논문 : AN Neural Algorithm of Artistic Style
    (키워드 : 중간데이터가 비슷해지도록 학습, 스타일행렬)
    연관 App: Prisma

-   이미지 생성  
    `DCGAN`(Deep Convolutinoal Generative Adversarial Network)

    **생성자**와 **식별자** 두개의 신경망을 이용해
    생성자는 **더 정교하게 가짜이미지 생성기술을 학습**하고
    식별자는** 더 정확하게 판단하는 감정기술을 학습**.(상호보완적)

이전에 소개한 ML은 `지도학습(supervised)`유형의 문제이다.

하지만 이번 절의 문제들은 labeling 된 dataset이 아닌 대량의 dataset만 주고,
`비지도학습`이 이루어 진것이다.

-   자율주행  
    `SegNet` 주위 사물인식

-   `강화학습`(`Deep Q network`)
    시행착오를 거치면서 학습하게 하는 분야다.
    `Agent`라는게 환경에 맞게 행동을 선택하면 환경이 변하고. 보상이 주어지면 더 나은 보상을 받는 쪽으로 행동을 바로잡는게 핵심이다.

    환경 --보상--> 에이전트
    환경 <--행동-- 에이전트

    이때의 보상은 지표로부터 역산해서 예상보상을 정해야한다.

    > `DQN`과 CNN을 이용하면 영상 프레임을 제공하고 각 동작의 가치를 출력할수있다.(게임화면 프레임을 제공하고 학습하도록 시키는 것)
