---
title: 'Training skill'
date: '2020-06-22'
category: ['딥러닝', '머신러닝']
draft: false
---

이번장에서 알아볼 Training Skill은 크게 다음과 같다.

-   **_가중치 매개변수의 최적화_** 방법,
-   **_매개변수 초깃값, 하이퍼파라미터(lr 등) 설정_**방법
-   **_overfitting의 대응책인 가중치 감소와 드롭아웃_**(정규화방법)
-   **_배치 정규화_**

---

### 매개변수 갱신

지금까지는 매개변수의 최적값을 `SGD(확률적 경사하강법)`을 통해서 찾아나갔다.
이런 SGD의 단점을 알아보고 다른 최적화기법을 사용해보자

#### SGD

`W = W - lr*gradient` 로 표현할수 있다.**_ 직관적으로 보면 기울어진 방향으로 일정거리 가겠다는 방법_**.

의사코드로 `SGD`를 사용하는 법을 작성해보면

```python
network = TwoLayerNet()
optimizer = SGD()

for i in range(10000):
    ...
    x_batch, t_batch = get_mini_batch(...) #미니배치
    grads = network.gradient(x_batch, t_batch)
    params = network.params
    optimizer.update(params, grads) #여기서 매개변수 갱신을 해준다.
```

이처럼 대부분의 DL 프레임워크에서는 최적화기법과 같은것을 **_모듈화_** 시켜놓고 사용하기 편하게 해준다(ex. Lasagne framework)

---

#### SGD

SGD는 단순하고 구현하기 쉽지만 문제에 따라서는 비효율적이다. 특히 `anisotropy function`(방향에따라 기울기가 달라지는 함수)에서는 탐색 경로가 비효율적이게 나올수있다.

---

### Momentum (모멘텀)

운동량을 뜻하는 만큼 물리와 관계가 있는데

`v = av - lr*gradient` (av는 아무 힘이 없을때 하강을 의미한다 중력가속도등)
`W = W + v` 즉 기울기방향으로 **_가속_**이 붙는다는 것을 고려한 식이다.

이렇게 구현하면 **_공이 바닥을 구르듯_** 움직이기때문에 SGD에 비해서 경로가 효율적이다.(**_기울기의 영향을 적게받는 축으로 고정된 힘을 받고있다고 가정_**하기때문에)

### AdaGrad

신경망학습에서는 **_학습률(lr)_** 값이 중요하다. 너무 작으면 학습시간이 길어지고, 너무 크면 발산으로 튕겨저 나간다

이 학습률을 정하는 기술로는 `learning rate decay` 가 있는데 학습을 진행하면서 점차 줄여가는 방법이다. 이때 매개변수 전체의 학습률을 일괄적으로 낮추는 방법이 있는데 이를 발전시킨게 `AdaGrad(각각의 매개변수에 맞춤형 값을 만든다)`

```python
h = h+gradient**2
W = W - lr*1/n^1/2*gradient
```

이처럼 **_h는 기울기값을 제곱해서 계속 더하여 매개변수를 갱신할때 기울기가 큰 원소(많이 움직인)에 대해서는 학습률을 낮게 적용_**한다. 즉 매개변수 원소마다 다르게 적용한다

그리고 **_계속 더해가는만큼 학습을 진행할수록 갱신 강도가 약해진다_**.
그래서 이를 개선한 기법이 `RMSPRop`라는 방법이 있다. 이 방법은 과거의 기울기는 점점 잊고 새로운 기울기를 크게 반영하는데, 이를 **지수이동평균**이라 하며 과거 기울기의 비중을 낮춰 주는 것이다.

따라서 갱신 경로를 확인해보면 이동이 큰 **y축 방향으로는 이후부터 속도를 줄여서 이동**하기 시작하고 x는 그에 비해 영향을 덜 받는 것을 알수 있다.

### Adam (Momentum + AdaGrad)

모멘텀처럼 물리적인 법칙을 이용하는 것과 더불어서 매개변수의 원소마다 적응적으로 갱신정도를 조정하는 AdaGrad 를 융합해서 만들었다.
2015년 제안되었는데 두방법을 조합한만큼 효율적인 탐색과 더불어 **_하이퍼파라미터의 편향 보정이 진행_**된다.

이처럼 `Adam`도 그릇바닥을 구르듯 움직이는데, `Momentum`보다 지그재그로 움직이는게 적다.`AdaGrad`를 적용한 효과이다.

> Adam은 하이퍼파라미터를 3개 설정하는데 하나는 지금까지의 학습률,(lr), 나머지 두개는 일차 모멘텀용 계수(0.9)와 이차 모멘텀용 계수(0.999)를 뜻한다.

위의 4가지 방법이 있지만 어떤 문제인지에 따라서, 하이퍼파라미터를 어떻게 설정하는가에 따라서도 달라진다.(신경망의 구조, 총 깊이에 따라서도)

지금으로써는 `SGD` 와 `Adam`을 많이 사용하고 있다.
그치만 **_더 일반적으로_** SGD보다 `Adam`이 더 빠르게 학습하고 최종 정확도도 높게 나타난다.

### 가중치의 초깃값

가중치의 초깃값을 무엇으로 설정하느냐에 따라 학습의 성패를 가르는 일이 많다.

-   `overfitting`을 억제해 범용 성능을 높이는 방법인 **가중치 감소**
    가중치 값을 작게해서 오버피팅이 일어나지 않도록 하는 것.

만약 그럼 초깃값을 0으로 설정하면 어떻게 될까? => 학습이 올바로 이뤄지지 않는다.

> ❔ 초깃값을 모두 0으로 해서 안되는 이유는?
> (정확히는 가중치를 균일값으로 설정하면 안되는 이유) 오차역전파법에서 모든 가중치의 값이 똑같이 갱신되기때문이다.  
> 즉 순전파로 갈때 두번째층의 뉴런에 같은 값이 가는데 이는 역전파로 돌아올때도 가중치가 모두 똑같이 갱신된다는 말이다. => 즉 갱신을 거쳐도 같은 값을 유지한다.(따라서 초깃값은 대칭적인 균형을 무너뜨리면서 무작위로 설정해줘야한다.)

-   은닉층의 **_활성화값(활성화함수의 출력데이터)_**의 분포를 관찰해보자
    활성화 함수로 시그모이드 함수를 사용하는 5층 신경망에 무작위로 생성한 input data를 넣어 각 층의 활성화 값의 분포를 확인해보자

일반적인 `sigmoid`를 사용해서 학습을 하게되면(표준편차 1) 활성화 값들이 0과 1에 치우쳐 분포가 되어있기때문에 역전파의 기울기 값이 점점 작아지다가 사라지는
`gradient vanishing`문제가 발생한다.

따라서 우리는 이러한 활성화값들이 특정 값에 치우친게 아닌 고르고 다양하게 분포해야지 올바른 학습을 할수 있다. 치우쳐서 같은 값을 출력한다는 것은 뉴런이 **_많아도 같은 값을 출력한다는 것이므로 의미가 없다_**.(**_표현력이 제한된다_**)

이러한 문제를 해결하기 위해서 가중치 초깃값을
`Xavier` 초깃값을 이용해서 설정해보자
(`Xavier` 초깃값은 일반적인 딥러닝 프레임워크에서 표준적으로 이용하고 있다.)
(Caffe 프레임워크는 가중치 초깃값을 설정할떄 args 로 xavier로 지정할수있다.)

주된 목적은 **각 층의 활성화값을 광범위하게 분포**시키는것이고 앞 계층의 노드가 n개이면 **_표준편차를 1/n^1/2로 사용_**하면 된다는 결론이 나온다
(논문에서는 다음층의 노드도 고려했지만 일반적으로 단순화해서 사용한다.)

> 단 이때 **_Xavier 초깃값은 활성화 함수가 선형_**인것을 전제로 한다(**_sigmoid 과 tanh는 좌우 대칭이라 중앙 부근에서 선형_**이다.)

### ReLU를 사용할때 초깃값

ReLU를 이용할때의 초깃값을 `He` 초깃값이라 한다.
그리고 초깃값은 앞층의 노드가 `n`일 때 `(2/n)^1/2` 로 주어진다.
(직관적으로 생각해보면 **ReLU는 0이하가 0이므로 이전의 sigmoid에 비해서 2배의 값이 필요하다**)
이를 통해서 가중치 값을 초기화하면 층이 깊어져도 활성화 값들이 치우치지 않고
**_기울기 소실_** 문제도 없어진다.(따라서 역전파때도 적절한 값이 나올 것이다.)

따라서 **_초깃값의 설정은 정말 중요한 문제_**이다.(신경망 학습의 성패를 결정짓는 경우도 많다.)

### 배치 정규화

위의 방법들은 가중치의 초깃값을 잘 설정하여 활성화 값을 퍼뜨린 반면
이번에는 **_강제로 활성화 값을 퍼뜨려_** 보도록 하자.

-   **_학습을 빨리 진행_**할수있다.
-   **_초깃값에 크게 의존하지 않는다_**
-   **_오버피팅을 억제_**한다

input data --> Affine --> `Batch Norm` --> ReLU --> Affine --> `Batch Norm` --> ReLU --> Affine --> Softmax

배치정규화는 미니배치를 단위로 정규화 해준다.(평균이 0, 분산이 1)
그리고 정규화된 data에 확대와 이동을 해줄수있는데
`y = Υx + β`
**_Υ가 확대_** **_β가 이동_**을 담당한다.(그냥 1차식 이동과 기울기 변화와 같은 개념이다.)
~~(배치 정규화의 역전파는 궁금하면 프레드릭 크레저트의 블로그를 찾아보자)~~

**_배치정규화_**를 시키면 거의 모든 경우에서 학습속도가 빨라지는데(무조건은 아니다) 이런 속도 뿐만아니라 가중치 초깃값에 크게 의존하지 않아도 된다.

### 바른 학습을 위해

-   `overfitting` : 신경망이 `training data`에만 지나치게 적응하여 그 이외의 data에는 제대로 대응하지 못하는 상태

overfitting의 원인

-   매개변수가 많고 표현력이 높은 모델
-   training data가 적은 모델

#### 해결방법

-   `가중치 감소`
    큰 가중치에 대해서 패널티를 부과해 `overfitting`을 억제하는 방법
    (오버피팅은 가중치의 매개변수가 커서 발생하는 경우가 많기때문)
    가중치의 `L2 norm(가중치의 제곱 norm)`을 손실함수에 더한다.
    가중치를 W라 하면 `L2 norm`에따른 가중치 감소는 `1/2λW^2`가 되고 이를 손실함수에 더한다

가중치감소는 모든 가중치 각각의 손실함수에 `1/2λW^2`를 더하는데 역전파에 따라 기울기를 계산할때는 미분한 `λW`를 더한다

> norm의 종류에는 `L2 norm`, `L1 norm`, `L∞` 가 있다.

-   `DropOut`  
    신경망 모델이 복잡해지면 가중치 감소만으로는 대응하기 어려워 지는데, 이럴때는 `Dropout`이라는 기법을 이용한다.

    Dropout은 **_뉴런을 임의로 삭제하면서 학습_**하는 방법
    **_훈련때는 data를 흘릴때마다 뉴런을 무작위로 삭제하고 시험할때는 모든 뉴런을 살려서 전달_**한다. Dropout의 효율적인 구현이 궁금하면
    Chainer 프레임워크의 드롭아웃 구현을 참고해보자

드롭아웃을 이용하면 **_표현력이 높아지면서도 overfitting_**을 억제할 수도 있다.

> ML에서는 `앙상블`을 **_애용하는데 개별적으로 학습시킨 여러 모델의 출력을 평균내어 추론하는 방식_**이다.
> 이는 드롭아웃과도 비슷하다고 볼수있는데, **_드롭아웃으로 매번 삭제하는 것을 새로운 네트워크라고 생각해주면 앙상블과 같은 방식_**이 되기 때문이다.

### 적절한 하이퍼파라미터 찾기

-   `검증데이터`
    **하이퍼파라미터를 검증할 때는 Testdata를 사용해서는 안된다.**
    ==> 왜냐하면 하이퍼파라미터가 Test data에 오버피팅 되기 때문이다.
    따라서 전용 테스트 데이터를 마련해놔야하는데 이를 검증데이터(**_validation data_**)라고 부른다
    (일반적으로는 Train data의 **_20%_**정도를 검증데이터로 빼서 검증한다.)

*   `최적화 과정`
    핵심은 **최적값이 존재하는 범위를 조금씩 줄여나가는 것**이다.
    줄여나가면서 그 범위에서 **무작위로 하이퍼파라미터 값을 골라낸(샘플링) 후 그 값으로 정확도를 평가**한다.

이 작업에서는 그리드 서치와 같은 규칙적인 탐색보다 **무작위로 샘플링해서 탐색하는게 더 좋은 결과를 낸다**.

이때의 범위는 대략적으로 지정하는것이 효과적인데
**_0.001 ~1,000 사이와 같이 10의 거듭제곱 단위로 범위를 지정_**한다.
그리고 이렇게 지정하는 것을 **_로그스케일로 지정한다_**고 한다.

**_하이퍼 파라미터 최적화에는 오랜시간이 걸릴 수 있다_**.
따라서 안 좋을 것 같은 값은 일찍 포기하고, **epoch 값을 작게하여** 1회 평가에 걸리는 시간을 단축하자

1. **_하이퍼파라미터 값의 범위를 설정_**한다
2. 설정된 범위에서 **_하이퍼파라미터의 값을 무작위로 추출_**
3. 1단계에서 **_샘플링한 하이퍼파라미터 값을 사용해 학습하고, 검증데이터로 정확도 평가한다(epoch 단위작게설정)_**
4. **1단계와 2단계를 특정횟수 반복하여 하이퍼파라미터의 범위를 좁혀간다**

> 조금더 세련된 기법으로는 `베이즈 최적화 기법`이있다.(베이즈 이론을 중심으로 하여 더 엄밀하고 효율적으로 최적화를 수행한다.)

```python
weight_decay = 10 ** np.random.uniform(-8,-4)
lr = 10** np.random.uniform(-6,-2)
```

위와같이 설정하여 **_반복하다가 검증데이터에 대한 정확도, 학습이 잘 진행되고있는 부분까지 파악하여 그 부근 범위의 하이퍼파라미터를 다시 학습하기 시작_**한다.

#### 👨‍💻실습코드

```python
class SGD:
    def __init__(self, lr=0.01):
        self.lr = lr

    def update(self, params, grads):
        for key in params.keys():
            params[keys] -= self.lr = grads[key]


class Momentum:
    def __init__(self, lr=0.01, momentum=0.9):
        self.lr = lr
        self.momentum = momentum
        self.v = None

    def updata(self, params, grads):
        if self.v is None:
            self.v = {}
            for key, val in params.items():
                self.v[key] = np.zeros_like(val)

        for key in params.keys():
            self.v[key] = self.momentum*self.v[key] - self.lr*grads[key]
            params[key] += self.v[key]

# 인스턴스 변수 v는 물체의 속도이다.
# update()가 호출될때 매개변수와 같은 구조의 data를 딕셔너리 변수로 저장


class AdaGrad:
    def __init__(self, lr=0.01):
        self.lr = lr
        self.h = None

    def update(self, params, grads):
        if self.h is None:
            self.h = {}
            for key, val in params.items():
                self.h[key] = np.zeros_like(val)
        for key in params.keys():
            self.h[key] += grads[key] * grads[key]
            params[key] -= self.lr * grads[key] / (np.sqrt(self.h[ey]) + 1e-7)

    # 마지막에 1e-7을 더하는 부분은 self.h[key]가 0이라해도 0으로 나누는 사태를 막는다.

```
